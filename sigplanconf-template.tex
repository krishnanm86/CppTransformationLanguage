%-----------------------------------------------------------------------------
%
%               Template for sigplanconf LaTeX Class
%
% Name:         sigplanconf-template.tex
%
% Purpose:      A template for sigplanconf.cls, which is a LaTeX 2e class
%               file for SIGPLAN conference proceedings.
%
% Guide:        Refer to "Author's Guide to the ACM SIGPLAN Class,"
%               sigplanconf-guide.pdf
%
% Author:       Paul C. Anagnostopoulos
%               Windfall Software
%               978 371-2316
%               paul@windfall.com
%
% Created:      15 February 2005
%
%-----------------------------------------------------------------------------


\documentclass[preprint]{sigplanconf}

% The following \documentclass options may be useful:

% preprint      Remove this option only once the paper is in final form.
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% numbers       To obtain numeric citation style instead of author/year.

\usepackage{amsmath}
\usepackage[ansinew]{inputenc}
\usepackage[pdftex]{graphicx}
\usepackage{url} 
\usepackage{wasysym}
\usepackage{stmaryrd}
\usepackage{listings}
\usepackage{proof}
\usepackage{tikz}
\usepackage{pgf}
\usetikzlibrary{backgrounds}
\usetikzlibrary{patterns, arrows, shapes, arrows.new, decorations.markings, fit, matrix, decorations.pathmorphing}
\tikzstyle{dflowarrow} = [very thick, double distance=1pt, > = triangle 45 new, arrow head=3mm]
\tikzstyle{choicearrow} = [thick, arrow head=3mm]
\tikzstyle{editarrow} = [thick, decorate, decoration=snake, > = triangle 45 new, arrow head=3mm]
\definecolor{dblue}{rgb}{0.0,0.0,0.6}
\usepackage{color}

\newcommand{\bincode}[1]{\texttt{\textcolor{blue}{#1}}}
\newcommand{\black}[1]{{\color{black}#1}}
\newcommand{\bincodeB}[1]{\texttt{\textbf{\textcolor{black}{#1}}}}

\newcommand{\implnote}[1]{\footnote{\textbf{Implementation note:} #1}}

\newcommand{\Prod}{::=}
\newcommand{\VB}{\ |\ }
\newcommand{\goesto}{$\longrightarrow$}
\newcommand{\defeq}{\stackrel{\Delta}{=}}
\newcommand{\tuple}[1]{\ensuremath{\langle #1 \rangle}}
\newcommand{\nt}[1]{\ensuremath{\langle\textit{#1}\rangle}}
\newcommand{\nti}[1]{\ensuremath{\textit{#1}}}
\newcommand{\keyword}[1]{{\textbf{#1}}}
\newcommand{\ID}{\textsf{id}}
\newcommand{\STRING}{\textsf{string}}
\newcommand{\CCTOKEN}{\textsf{cctoken}}
\newcommand{\Literal}[1]{\textrm{`\texttt{#1}'}}

\newcommand{\dflowto}{\ensuremath{\rhd}}
\newcommand{\expandsto}{\ensuremath{\doteq}}
\newcommand{\types}{\ensuremath{:\hspace{-0.11cm}\Yright}}
%\newcommand{\tags}{\ensuremath{}}

\newcommand{\transto}{\texttt{==>}}
\newcommand{\transfrom}{\texttt{<==}}
\newcommand{\bbegin}{\texttt{\{\{}}
\newcommand{\bend}{\texttt{\}\}}}
\newcommand{\lend}{\texttt{;;}}

\newcommand{\cons}[1]{\textsc{#1}}
\newcommand{\nodety}[1]{\textcolor{dblue}{\textsf{#1}}}

\renewcommand*\ttdefault{txtt}

\definecolor{dblue}{rgb}{0,0,0.6}
\definecolor{dgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
 
 


\usepackage[plainpages=false,pdfpagelabels]{hyperref}
\usepackage{textcomp}

\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{CONF 'yy}{Month d--d, 20yy, City, ST, Country}
\copyrightyear{20yy}
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm}
\copyrightdoi{nnnnnnn.nnnnnnn}

% Uncomment the publication rights you want to use.
%\publicationrights{transferred}
%\publicationrights{licensed}     % this is the default
%\publicationrights{author-pays}

\titlebanner{}        % These are ignored unless
\preprintfooter{}   % 'preprint' option specified.

\title{Interactive API Migration Framework}
\subtitle{}

\authorinfo{Krishna Narasimhan, Christoph Reichenbach}
           {Goethe University, Frankfurt}
           {krishna.nm86@gmail.com, creichen@gmail.com}
\authorinfo{Julia Lawall}
           {INRIA, Paris}
           {Julia.Lawall@lip6.fr}

\maketitle

\begin{abstract}
This is the text of the abstract.
\end{abstract}

\category{CR-number}{subcategory}{third-level}

% general terms are not compulsory anymore,
% you may leave them out
\terms
term1, term2

\keywords
keyword1, keyword2

\section{Introduction}
As source code evolves, large scale transformations are unavoidable. These can be a result of the need to introduce a new API, upgrade usages of existing API, perform code optimizations or simply do a code clean-up. Current support for such transformations come in the form of refactorings from Integrated Development environments, transformation languages or simply domain specific libraries. A scenario that occurs frequently during code evolution is migration of types, either to exploit enhanced capabilities as part of a library, or simply getting rid of a datatype that is hard to manage relative to the goals of the software. Examples of them include migrating from single precision numeric types to multiple precision types by introducing the GMP library, or explicitly vectorizing arrays and loops by introducing the VC library, or simply migrating usages of character pointer to strings. 
                             Transformations of such nature are generally not simple cut and replace of method calls or declarations. They require non-linear tracking of dependencies, transforming code belonging to different kinds of syntactic classes and tracking information between transformations. Partially performing such transformations could potentially result in semantically and/or syntactically broken code. Consider the scenario of explicitly vectorizing a array of struct of floats using the VC API. The VC API provides a custom type called float\_v, which is a float vector, with capability to hold more than one float, depending on the hardware implementation. Transforming the array of struct of floats would involve transforming the individual members of the struct definition into float vectors, using the information about the member types to construct a new reduced size for the array and transforming all usages of the array object if possible. Similar problems of dependency tracking and propagating information across transformations exist even with the other examples we take motivation from. 
              The existing refactorings in IDEs are limited by the fixed features of the environment and can only be triggered one at a time. For example, Eclipse supports a fixed set of refactorings like "Extract function" or "Rename method".  IDE refactorings do not support expressing pattern matching and rewriting of different syntactic classes. It would require the developer to write extensive scripts to even trigger multiple refactorings in a specific order.  Transformation languages like Stratego/XT and Coccinelle allow specifying transformation rules to express generic patterns matches and code transformations. Stratego/XT uses term rewriting and strategies to express the transformations. Strategies are simply combinations of term rewriting rules. Although Stratego/Xt is very powerful, it is limited when it comes to propagating information between rules, as is required when expressing the transformation of the array of structs in the VC example. Coccinelle allows elegant expression of code fragment rewriting in the form of diffs and permits propagating information between rules with rule parameters that can be updated within the rules and queried by other rules. But, Coccinelle does not support search through dependencies.
              We propose to design a language that can be used to express pattern matching and rewriting rules in the form of term equivalences. We specify how rules can be written in the language and introduce features that can be used to express propagating information across rules. The user can trigger a tool by providing a starting point, which is a combination of a code location and a set of rules (specifications) written in the language. The tool would attempt to apply a rule or ask the user if multiple rules can be applied to the location. The tool would then look through the dependencies of the transformed code and suggest applicable rules for those code locations. The process continues till the all code dependencies are exhausted or if the user chooses to stop the application of rules. The motivation of such a language and complementary tool is as follows:
\begin{itemize}
\item The expert user who writes the specifications has the freedom to write only partial specifications, which he can later update.
\item The end user can use any set of specifications and has the freedom to choose where and how far to apply them and how much to manually transform.
\end{itemize}
The tool can provide an option to roll back if the user is not happy with the state of transformations.

\section{Motivating Examples}
\subsection{Using the GMP library to transform a single precision factorial into a multi precision factorial}
Consider the scenario of converting a function that computes the factorial of a given integer \textbf{Figure \ref{fig-gmp}} to be able to return a multi-precision numerical using the GNU's GMP library. Here is a sample before and after code of such a scenario.
\begin{figure*}
  \begin{tikzpicture}
\node[text width=7.5cm] at (-5, 0) (F1) {
\begin{lstlisting}[language = C++,
frame=single,
numbers=none]
int fact(int n){
  int i;
  int p = 1;
  for (i=1; i <= n ; ++i){
    p = p * i;
  }
  return p;
}
\end{lstlisting}
};

\node[text width=7.5cm] at (4, 0) (F2) {
\begin{lstlisting}[ language = C++,
frame=single,
numbers=none]
 mpz_t fact(int n){
  int i;
  mpz_t p;
  mpz_init_set_ui(p,1);
  for (i=1; i <= n ; ++i){
     mpz_mul_ui(p,p,i);
   }
   return p;
}
\end{lstlisting}
};
\draw[ultra thick, double distance=1pt, ->, > = angle 90] (F1) -- (F2);
\end{tikzpicture}
\caption{Integer to BigInteger conversion using GMP}
\label{fig-gmp}
\end{figure*}
The main steps a developer going from int to multi precision integer would do are:
\begin{itemize}
\item Flag the return value, find it's initialization and transform the initialization \textbf{int p = 1}. He would then need to use two function calls to transform the initialization into a vector version.
\item Search for usages of this newly transformed value and transform it's operations to reflect multi precision usages. In the above case, the developer would need to convert the assignment \textbf{p = p *i;}  into \textbf{mpz\_mul\_ui(p,p,i);} 
\item Change the return type to reflect the type of the new value being returned.
\end{itemize}

The two key features an automation framework would require to support transformations are :
Ability to support expressing transformation rules for pattern matching and rewriting different syntactic classes. 
Ability to walk through dependencies of transformations performed and then trigger transformation rules on the dependencies, if applicable and roll back the whole transformation, if no transformation rules are applicable.

\subsection{Introducing the VC API}
Consider another scenario where c++ code undergoes explicit vectorization using an API called VC \textbf{\ref{fig-vc}}. This api provides vector versions of primitive types and corresponding operations. Here is a simple example of a code undergoing transformation from scalar to a VC version.
\begin{figure*}

 \begin{tikzpicture}
\node[text width=7.5cm] at (-5, 0) (F1) {
\begin{lstlisting}[language = C++,
frame=single,
numbers=none]
struct A
{
    int x;
} 
A aobj[1000];

struct B
{
    int y;
} 
B bobj[1000];

void fn()
{
   for(int i=0; i<1000; i++)
   {
        float temp = aobj[i].x;
        bobj[i].y = std::sqrt(temp);
   }
}
\end{lstlisting}
};

\node[text width=7.5cm] at (4, 0) (F2) {
\begin{lstlisting}[ language = C++,
frame=single,
numbers=none]
struct Av
{
    int xv;
} 
Av aobjv[1000/float_v::size];

struct Bv
{
    int yv;
} 
Bv bobjv[1000/float_v::size];

void fn()
{
   for(int i=0; i<1000/float_v::size; i++)
   {
        float_v tempv = aobjv[i].xv;
        bobjv[i].yv = vc::sqrt(tempv);
   }
}
\end{lstlisting}
};
\draw[ultra thick, double distance=1pt, ->, > = angle 90] (F1) -- (F2);
\end{tikzpicture}
\caption{Introducing VC}
\label{fig-vc}
\end{figure*}
The developer would need to perform many steps in order to transform the code in the left hand side to the one in the right hand side. Much of the steps and the features required can be categorized into one of the two features we listed with the example above. But the interesting bits are :
\begin{itemize}

\item The developer would need to analyse the type of \textbf{aobj} , and transform the definition of the \textbf{struct A}, as it comprises only of float members.
\item This transformation of the size of the array \textbf{aobj} also involves collecting the information about the type of the members inside the struct, \textbf{float} and using the vc version of it to construct the new size. 
\item Similarly, the user would also need to collect the information about the type of all array indexed elements inside the array in order to transform the limit of the for statement. 

\end{itemize}
The key feature that can be extracted out of the above listed steps is :
\begin{itemize}
\item Ability to collect information from one transformation and pass it on to transformations in other parts of the code.
\end{itemize}

\section{Features in the envisioned Language}
We summarize the features that have been extracted out of the analysis of the two api migration examples.
\begin{enumerate}
\item Pattern matching and code rewriting
\item Automatic search of dependencies of the transformations
\item Information propagation across transformation patterns
\end{enumerate}
We propose to use the following language features to support the generic features that we extracted out of the examples.
\begin{enumerate}
\item Pattern matching and rewriting - Transformation rules in the form of equivalences
\item Information propagation across rules - Tags 
\item Search through dependencies - Implicit
\end{enumerate}

In order to understand how the language introduces the equivalences and tags, let us look at the transformation of struct example \textbf{Figure \ref{fig-vc2}}.


\begin{figure*}

 \begin{tikzpicture}
\node[text width=7.5cm] at (-5, 0) (F1) {
\begin{lstlisting}[language = C++,
frame=single,
numbers=none]
struct A
{
    int x;
} 
A aobj[1000];
\end{lstlisting}
};

\node[text width=7.5cm] at (4, 0) (F2) {
\begin{lstlisting}[ language = C++,
frame=single,
numbers=none]
struct Av
{
    int xv;
} 
Av aobjv[1000/float_v::size];
\end{lstlisting}
};
\draw[ultra thick, double distance=1pt, ->, > = angle 90] (F1) -- (F2);
\end{tikzpicture}
\caption{Introducing VC}
\label{fig-vc2}
\end{figure*}
\begin{figure*}

\begin{lstlisting}
tag type  vctype;;

//TTL Expression skeleton to transform array of structs. - Block B
declaration struct $structname$ {$body$}[$s$] === 
          struct $structname$v {vc_struct($body$)}[$s$/(vc_struct,vctype)::size])

//Block of rules to transform body of struct definition + updating the value of structtype- Block C
scope  vc_struct{{   
  statement  int $a$; === {{vctype:=int_v}}  $a$v;
  statement  float $a$; === {{vctype:=float_v}}  $a$v; 
 }}
\end{lstlisting}

\caption{Specification sample}
\label{fig-spec}
\end{figure*}

In the example specification at \textbf{Figure \ref{fig-spec}}, the first line is an example of a tag declaration. The tag, called vctype can be used to propagate a type information. 
The block B is an example of an pattern match and rewriting rule. It matches a declaration of a struct definition with size $s and body $body. It is rewritten into a new struct definition, with the rewrite rules on the right hand side of === sign.

The scope vc\_struct defines the rules that must be applied on each statement declaring a member type which is either an int or a float. It also populates the vc version of the type of the member declaration, if it matches with the existing value of vctype. This is referenced and used in the transformation of the size. The vc\_struct also transforms the member declarations into the new vc types. 


\appendix
\section{Appendix Title}

This is the text of the appendix, if you need one.

\acks

Acknowledgments, if needed.

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrvnat}

% The bibliography should be embedded for final submission.

\begin{thebibliography}{}
\softraggedright

\bibitem[Smith et~al.(2009)Smith, Jones]{smith02}
P. Q. Smith, and X. Y. Jones. ...reference text...

\end{thebibliography}


\end{document}
